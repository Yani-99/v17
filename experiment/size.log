
⚠️ 警告: 未检测到 HF_TOKEN 环境变量。
建议在终端运行: export HF_TOKEN='your_hf_token'

==================================================
实验组 1 - 正在处理基座模型: roberta-large
  > 正在查询基座模型纯权重大小...
  > 正在查询微调模型: roberta-large-mnli ...
  > 正在查询微调模型: deepset/roberta-large-squad2 ...
  > 正在查询微调模型: cross-encoder/stsb-roberta-large ...
  > 正在查询微调模型: siebert/sentiment-roberta-large-english ...
  > 正在查询微调模型: sentence-transformers/all-roberta-large-v1 ...
  > 正在查询微调模型: ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli ...
  > 正在查询微调模型: openai-community/roberta-large-openai-detector ...
  > 正在查询微调模型: navteca/roberta-large-squad2 ...
  > 正在查询微调模型: cross-encoder/quora-roberta-large ...
  > 正在查询微调模型: jean-baptiste/roberta-large-ner-english ...

【纯权重统计结果 - 组 1】
  基准参考: 基座模型单体纯权重大小 = 1.32 GB

  ▶ 场景 A: 仅计算前 5 个微调模型
    - 粗略估计大小 (基座*5) : 6.62 GB
    - 真实总占用纯权重大小  : 6.62 GB
    - 结论: 粗略估计比实际【多算了】 0.00 GB

  ▶ 场景 B: 仅计算全部 10 个微调模型
    - 粗略估计大小 (基座*10): 13.24 GB
    - 真实总占用纯权重大小  : 13.24 GB
    - 结论: 粗略估计比实际【多算了】 0.00 GB

==================================================
实验组 2 - 正在处理基座模型: meta-llama/Llama-3.1-70B
  > 正在查询基座模型纯权重大小...
  > 正在查询微调模型: meta-llama/Llama-3.1-70B-Instruct ...
  > 正在查询微调模型: NousResearch/Hermes-3-Llama-3.1-70B ...
  > 正在查询微调模型: nvidia/Llama-3.1-Nemotron-70B-Instruct-HF ...
  > 正在查询微调模型: unsloth/Meta-Llama-3.1-70B-Instruct ...
  > 正在查询微调模型: mattshumer/Reflection-Llama-3.1-70B ...
  > 正在查询微调模型: VAGOsolutions/Llama-3.1-SauerkrautLM-70b-Instruct ...
  > 正在查询微调模型: allenai/Llama-3.1-Tulu-3-70B-SFT ...
  > 正在查询微调模型: nvidia/OpenMath2-Llama3.1-70B ...
  > 正在查询微调模型: migtissera/Tess-3-Llama-3.1-70B ...
  > 正在查询微调模型: mylesgoose/Llama-3.1-70B-Instruct-abliterated ...

【纯权重统计结果 - 组 2】
  基准参考: 基座模型单体纯权重大小 = 131.42 GB

  ▶ 场景 A: 仅计算前 5 个微调模型
    - 粗略估计大小 (基座*5) : 657.08 GB
    - 真实总占用纯权重大小  : 788.50 GB
    - 结论: 粗略估计比实际【少算了】 131.42 GB

  ▶ 场景 B: 仅计算全部 10 个微调模型
    - 粗略估计大小 (基座*10): 1314.17 GB
    - 真实总占用纯权重大小  : 1445.58 GB
    - 结论: 粗略估计比实际【少算了】 131.42 GB

