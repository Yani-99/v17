-- Found pybind11: /home/liu4441/.conda/envs/liana/lib/python3.9/site-packages/pybind11/include (found version "3.0.1")
-- Configuring done (0.2s)
-- Generating done (0.0s)
-- Build files have been written to: /home/newdrive/liu4441/liana/pfor/standard/v17/build
[100%] Built target pforex_cpp
[RUN] Running benchmarks...
[CONFIG] 手动设定: 启动 1 个并行线程

>>> Running Config: mistral-7b-1 <<<
Detecting FT model native dtype...
-> Found dtype in config: torch.bfloat16

[========== Rate: 0.0 = Model: mistral-7b-1==========]
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
  -> Size: 40.69% | Comp: 273.4 MB/s | Decomp: 349.9 MB/s | Metrics: {}

>>> Running Config: mistral-7b-2 <<<
Detecting FT model native dtype...
-> Found dtype in config: torch.bfloat16

[========== Rate: 0.0 = Model: mistral-7b-2==========]
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
  -> Size: 31.62% | Comp: 302.1 MB/s | Decomp: 365.2 MB/s | Metrics: {}

>>> Running Config: mistral-7b-3 <<<
Detecting FT model native dtype...
-> Found dtype in config: torch.bfloat16

[========== Rate: 0.0 = Model: mistral-7b-3==========]
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
  -> Size: 31.69% | Comp: 303.2 MB/s | Decomp: 363.3 MB/s | Metrics: {}

>>> Running Config: mistral-7b-4 <<<
Detecting FT model native dtype...
-> Found dtype in config: torch.float16

[========== Rate: 0.0 = Model: mistral-7b-4==========]
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
  -> Size: 41.01% | Comp: 303.7 MB/s | Decomp: 372.7 MB/s | Metrics: {}

>>> Running Config: mistral-7b-5 <<<
Detecting FT model native dtype...
-> Found dtype in config: torch.bfloat16

[========== Rate: 0.0 = Model: mistral-7b-5==========]
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396768768 bytes required
  - 1: 524320768 bytes required
  - 2: 524320768 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
  -> Size: 31.84% | Comp: 302.4 MB/s | Decomp: 367.2 MB/s | Metrics: {}

>>> Running Config: mistral-7b-6 <<<
Detecting FT model native dtype...
-> Found dtype in config: torch.bfloat16

[========== Rate: 0.0 = Model: mistral-7b-6==========]
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
  -> Size: 32.50% | Comp: 300.3 MB/s | Decomp: 365.4 MB/s | Metrics: {}

>>> Running Config: mistral-7b-7 <<<
Detecting FT model native dtype...
-> Found dtype in config: torch.bfloat16

[========== Rate: 0.0 = Model: mistral-7b-7==========]
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
  -> Size: 37.61% | Comp: 285.0 MB/s | Decomp: 355.4 MB/s | Metrics: {}

>>> Running Config: mistral-7b-8 <<<
Detecting FT model native dtype...
-> Found dtype in config: torch.bfloat16

[========== Rate: 0.0 = Model: mistral-7b-8==========]
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396768768 bytes required
  - 1: 524320768 bytes required
  - 2: 524320768 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
  -> Size: 23.06% | Comp: 311.6 MB/s | Decomp: 382.8 MB/s | Metrics: {}

>>> Running Config: mistral-7b-9 <<<
Detecting FT model native dtype...
-> Found dtype in config: torch.float16

[========== Rate: 0.0 = Model: mistral-7b-9==========]
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
  -> Size: 37.18% | Comp: 320.1 MB/s | Decomp: 379.7 MB/s | Metrics: {}

>>> Running Config: mistral-7b-10 <<<
Detecting FT model native dtype...
-> Found dtype in config: torch.float32

[========== Rate: 0.0 = Model: mistral-7b-10==========]
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396736000 bytes required
  - 1: 524288000 bytes required
  - 2: 524288000 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 1396752384 bytes required
  - 1: 524304384 bytes required
  - 2: 524304384 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
  -> Size: 75.11% | Comp: 414.5 MB/s | Decomp: 402.5 MB/s | Metrics: {}
